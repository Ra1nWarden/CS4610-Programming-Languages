I use ply with python for this programming assignment. All symbols such as "+-*/" etc are separated types. This is to make the printing easier. Another umbrella type called "identifier" is set up to match all strings starting with alphabets in both lower or upper cases. After that, the matched strings are tested again to find the exact types. I have a special type called "keyword" which includes all the reserved words in Cool. The matched identifier is set to lower case to match the keywords. If not found, it is set as either a type or identifier. Integers are checked for out of bound errors and leading zeros are emitted.
My implementation of the lexer uses different states to handle strings and comments. Whenever a " character is scanned, the lexer goes into string state. Inside this string mode, I set special rules for the lexer. For example, I use the regular expression r'\\.' to ignore any character after \. In this way, all \" sequences are ignored. The error for the string state is the EOF character. The lexer quits string state when it sees another " character. Similarly for comments, the lexer enters the comment state when it sees (*. Initially, there is a field level inside the lexer to count the level of nested comments. Inside this state, the level increases by 1 when it reads another (* and the level decreases by 1 when it reads *). When the level reaches 0, the lexer quits the string state and go back to the original state.
As for test cases, firstly I test nested comments with multiple levels of (* and *). Also, test case for strings with escape characters is another important test case. Moreover, I test case insensitivity for key words except true and false. Special test cases such as "True" and "fAlse" are used as well. For negative test cases, illegal characters such as null character, "|" etc are tested. The terminal outputs are checked for correct line number reporting.
